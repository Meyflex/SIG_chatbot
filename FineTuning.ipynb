{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce81f25-c33b-4e3c-b136-ae5d5b7700f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments \n",
    "from trl import SFTTrainer  # Import SFTTrainer for instruction-based fine-tuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5b71a1-960f-4237-a304-9c16191d7ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4fde5-108a-4be3-bcca-2b0de5bf1df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87275987-709f-4924-918f-a40f26e8f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'ARC-101', 'output': \"Cela correspond au Retrait de lignes dans la table tampon de l’archivage. Ce traitement permet de supprimer des lignes de la table A_ARC_DONNEE à partir des ID des objets qu'elles représentent.\"}\n"
     ]
    }
   ],
   "source": [
    "data_path = 'niagara.data'  # Update with your file path\n",
    "data = pd.read_csv(data_path, sep=';', header=None, names=['Code', 'Description', 'Lien', 'Detail', 'Flag'], on_bad_lines='skip')\n",
    "data['input'] =   data['Code'] \n",
    "data['output'] = data.apply(lambda row: \"Cela correspond \"+ \n",
    "                            (\"à l'\" if isinstance(row['Description'], str) and row['Description'][0].lower() in 'aeiou' else \"au \") + \n",
    "                            str(row['Description']) + \". \" + str(row['Detail']), axis=1)\n",
    "\n",
    "# Create a Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(data[['input', 'output']])\n",
    "\n",
    "print(dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22494429-7d9b-4c21-ab9b-51f6edbb0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(sample):\n",
    "  bos_token = \"<s>\"\n",
    "  system_message = \"\"\"[INST] À partir de la description détaillée fournie, identifiez et donnez le titre exact de la documentation qui correspond à cette description. Si vous n'êtes pas certain de la réponse exacte, fournissez une idée des éléments les plus proches qui pourraient correspondre à la description. Dans le cas où aucune correspondance n'est trouvée ou si vous ne connaissez pas la documentation correspondante, répondez simplement par 'Je ne connais pas cela'.\"\"\"\n",
    "  response = sample[\"output\"]\n",
    "  input = sample[\"input\"]\n",
    "  eos_token = \"</s>\"\n",
    "\n",
    "  full_prompt = \"\"\n",
    "  full_prompt += bos_token\n",
    "  full_prompt += system_message\n",
    "  full_prompt += \"\\n\" +  response\n",
    "  full_prompt += \"[/INST]\"\n",
    "  full_prompt += input\n",
    "  full_prompt += eos_token\n",
    "\n",
    "  return full_prompt\n",
    "\n",
    "def create_combined_bidirectional_prompt(sample):\n",
    "    # Définition des parties du prompt\n",
    "    bos_token = \"<s>\"\n",
    "    eos_token = \"</s>\"\n",
    "    \n",
    "    # Instruction pour Titre vers Description\n",
    "    system_message_title_to_description = \"[INST] Donnez la description détaillée correspondant au titre suivant correspondant au titre d'une documentation du porjet SIG.\"\n",
    "    title = sample[\"input\"]  # Assurez-vous que 'sample' contient un champ 'title'\n",
    "    \n",
    "    # Instruction pour Description vers Titre\n",
    "    system_message_description_to_title = \"\"\"[INST] Identifiez et donnez le titre exact de la documentation correspondant à la description suivante. Si vous n'êtes pas certain de la réponse exacte, fournissez une idée des éléments les plus proches qui pourraient correspondre à la description. Dans le cas où aucune correspondance n'est trouvée ou si vous ne connaissez pas la documentation correspondante, répondez simplement par 'Je ne connais pas cela'.\"\"\"\n",
    "    description = sample[\"output\"]  # Assurez-vous que 'sample' contient un champ 'description'\n",
    "    \n",
    "    # Création et combinaison des deux prompts\n",
    "    combined_prompt = f\"{bos_token}{system_message_title_to_description}\\n Titre: {title} [/INST] \\n Description: {description}{eos_token} \"\n",
    "    # combined_prompt += f\"{system_message_description_to_title}\\n Description: {description} [/INST] \\n Titre: {title} \"\n",
    "    \n",
    "    return combined_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2e1f0b-6829-492b-a47a-bc7790782359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>[INST] Donnez la description détaillée correspondant au titre suivant correspondant au titre d'une documentation du porjet SIG.\\n Titre: ARC-101 [/INST] \\n Description: Cela correspond au Retrait de lignes dans la table tampon de l’archivage. Ce traitement permet de supprimer des lignes de la table A_ARC_DONNEE à partir des ID des objets qu'elles représentent.</s> \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_combined_bidirectional_prompt(dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6768e7-32c3-4816-862b-389275cc4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7228b08-a28d-41b8-a785-03e62d68d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc4f046-775a-439a-8a36-4e5503d8b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174c69358df444e094cfdb5c4ea40cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4c5d2a-b44a-4c8d-a2a4-17634814a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa833542-7e68-4c28-b797-626376075919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "    \n",
    "    encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "    model_inputs = encoded_input.to('cuda')\n",
    "    \n",
    "    generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=1024,\n",
    "                                 do_sample=True,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "    \n",
    "    return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fdf3f6-9a0c-4789-ae32-d9e583e3cb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>  Le titre \"ARC-101\" est plutôt générique et peut correspondre à différentes choses selon le contexte. Voici quelques exemples de description détaillée possible en fonction des domaines d\\'application :\\n\\n1. Dans le domaine de la construction et de l\\'architecture, ARC-101 pourrait se référer à un type de béton renforcé ou à un système de poutres en acier utilisés dans la construction de bâtiments ou d\\'infrastructures.\\n2. En électronique et en ingénierie, ARC-101 pourrait être le nom d\\'un circuit intégré ou d\\'un composant spécifique utilisé dans l\\'assemblage de cartes électroniques.\\n3. Dans le domaine de la chimie et de la physique, ARC-101 pourrait être le nom d\\'une molécule ou d\\'un matériau spécifique utilisé dans la recherche scientifique ou dans l\\'industrie.\\n4. Dans le domaine de la formation et de l\\'éducation, ARC-101 pourrait être le code ou le nom d\\'un cours d\\'introduction à l\\'architecture ou à l\\'ingénierie, offrant les bases théoriques et pratiques de la conception et de la construction de structures.\\n5. Dans le domaine de la sécurité et de la défense, ARC-101 pourrait être le nom d\\'une arme ou d\\'un équipement spécifique utilisé par les forces de l\\'ordre ou les militaires.\\n\\nCes exemples ne sont bien sûr pas exhaustifs et le titre ARC-101 pourrait avoir une signification différente dans un contexte différent. En l\\'absence de précision, il est donc nécessaire de demander des éclaircissements sur la signification du titre pour une description détaillée appropriée.</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=\"\"\"[INST] Donnez la description détaillée correspondant au titre suivant.\\n Titre: ARC-101 [/INST]\"\"\"\n",
    "\n",
    "generate_response(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9477821-b161-4e46-8fee-f79497a6ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_prompts(prompt):\n",
    "    return tokenizer(create_combined_bidirectional_prompt(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ed1b6e-8f4b-4360-b664-59c628c84a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee5c72fba994dfd8520c6dd0907a301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f235a904cb94c14b0a25062b69f82b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.1)  # Séparer les données en set d'entraînement et de test\n",
    "tokenized_train_dataset = dataset.map(tokenize_prompts)\n",
    "tokenized_val_dataset = train_test_split['test'].map(tokenize_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4657808f-b66d-45f9-b16c-5bd155b24f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=50, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    # plt.xlim([0, 1500])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1c2c4aa-d9ff-4b07-9e46-fc8cc41e6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "        target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a6575c0-5350-421e-84e9-1a4bf8fc045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2de8d743-1d91-494e-bfd4-962eaa97b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14209024 || all params: 23496810496 || trainable%: 0.06047213940981005\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "131383dd-5821-4972-89c2-77b4053c24b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PeftModelForCausalLM(\n",
      "      (base_model): LoraModel(\n",
      "        (model): MixtralForCausalLM(\n",
      "          (model): MixtralModel(\n",
      "            (embed_tokens): Embedding(32000, 4096)\n",
      "            (layers): ModuleList(\n",
      "              (0-31): 32 x MixtralDecoderLayer(\n",
      "                (self_attn): MixtralFlashAttention2(\n",
      "                  (q_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (k_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (v_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (o_proj): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (rotary_emb): MixtralRotaryEmbedding()\n",
      "                )\n",
      "                (block_sparse_moe): MixtralSparseMoeBlock(\n",
      "                  (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
      "                  (experts): ModuleList(\n",
      "                    (0-7): 8 x MixtralBLockSparseTop2MLP(\n",
      "                      (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                      (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                      (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                      (act_fn): SiLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (input_layernorm): MixtralRMSNorm()\n",
      "                (post_attention_layernorm): MixtralRMSNorm()\n",
      "              )\n",
      "            )\n",
      "            (norm): MixtralRMSNorm()\n",
      "          )\n",
      "          (lm_head): lora.Linear(\n",
      "            (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=16, out_features=32000, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa814362-e553-450a-9977-234dfdd05b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    print(torch.cuda.device_count())\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54ffb38a-428a-4962-aeb2-76727286405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "  output_dir = \"./Mixtral_45b_SIG_v3\",\n",
    "  #num_train_epochs=5,\n",
    "  max_steps = 500, # comment out this line if you want to train in epochs\n",
    "  per_device_train_batch_size = 16,\n",
    "  warmup_steps = 0.03,\n",
    "  logging_steps=10,\n",
    "  save_strategy=\"epoch\",\n",
    "  #evaluation_strategy=\"epoch\",\n",
    "  evaluation_strategy=\"steps\",\n",
    "  eval_steps=10, # comment out this line if you want to evaluate at the end of each epoch\n",
    "  learning_rate=2.5e-5,\n",
    "  bf16=True,\n",
    "  # lr_scheduler_type='constant',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc2e1bb9-179f-45a8-9857-6c9b383f0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 1024\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "  model=model,\n",
    "  peft_config=peft_config,\n",
    "  max_seq_length=max_seq_length,\n",
    "  tokenizer=tokenizer,\n",
    "  packing=True,\n",
    "  formatting_func=create_prompt, # this will aplly the create_prompt mapping to all training and test dataset\n",
    "  args=args,\n",
    "  train_dataset=dataset,\n",
    "  eval_dataset=train_test_split['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e27d0f-9d4e-49f8-bb2f-4555b747fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/500 15:39 < 54:35, 0.12 it/s, Epoch 4.87/22]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.352400</td>\n",
       "      <td>1.436042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>1.210535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>1.107445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.911800</td>\n",
       "      <td>1.047539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.854200</td>\n",
       "      <td>1.003148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>0.963458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.790300</td>\n",
       "      <td>0.922513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.762300</td>\n",
       "      <td>0.881547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.836425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.658600</td>\n",
       "      <td>0.790172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.750816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3cbd8-141c-47fe-81c3-0ce9e2717ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./Mixtral_45b_SIG_es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8744141-b479-4faf-8644-bd91282fc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0057dfe9-75a2-448c-b498-a02427f191fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0898d7ea067e42bda53b3acd157091d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a6c15-a0e5-4983-8d98-509446e3858f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9d62ef7-500e-4581-bf22-faa9b153812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8325df0e814bd0a7ac3b9fbc01ef8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecad84d133c44e3accc431959acc7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/752M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b60b5c4fc44eda82785b8f509ed412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeyflex/Mixtral_SIG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:384\u001b[0m, in \u001b[0;36mSFTTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mOverwrite the `push_to_hub` method in order to force-add the tag \"sft\" when pushing the\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mmodel on the Hub. Please refer to `~transformers.Trainer.push_to_hub` for more details.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m trl_sanitze_kwargs_for_tagging(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tag_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tag_names, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/transformers/trainer.py:3753\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3751\u001b[0m \u001b[38;5;66;03m# Wait for the current upload to be finished.\u001b[39;00m\n\u001b[1;32m   3752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n\u001b[0;32m-> 3753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupload_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_as_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPREFIX_CHECKPOINT_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:1235\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:4812\u001b[0m, in \u001b[0;36mHfApi.upload_folder\u001b[0;34m(self, repo_id, folder_path, path_in_repo, commit_message, commit_description, token, repo_type, revision, create_pr, parent_commit, allow_patterns, ignore_patterns, delete_patterns, multi_commits, multi_commits_verbose, run_as_future)\u001b[0m\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;66;03m# Defining a CommitInfo object is not really relevant in this case\u001b[39;00m\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;66;03m# Let's return early with pr_url only (as string).\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pr_url\n\u001b[0;32m-> 4812\u001b[0m commit_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4815\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4824\u001b[0m \u001b[38;5;66;03m# Create url to uploaded folder (for legacy return value)\u001b[39;00m\n\u001b[1;32m   4825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_pr \u001b[38;5;129;01mand\u001b[39;00m commit_info\u001b[38;5;241m.\u001b[39mpr_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:1235\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:3775\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   3772\u001b[0m \u001b[38;5;66;03m# If updating twice the same file or update then delete a file in a single commit\u001b[39;00m\n\u001b[1;32m   3773\u001b[0m _warn_on_overwriting_operations(operations)\n\u001b[0;32m-> 3775\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreupload_lfs_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munquoted_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# first-class methods take unquoted revision\u001b[39;49;00m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfree_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# do not remove `CommitOperationAdd.path_or_fileobj` on LFS files for \"normal\" users\u001b[39;49;00m\n\u001b[1;32m   3784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3785\u001b[0m files_to_copy \u001b[38;5;241m=\u001b[39m _fetch_files_to_copy(\n\u001b[1;32m   3786\u001b[0m     copies\u001b[38;5;241m=\u001b[39mcopies,\n\u001b[1;32m   3787\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3791\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m   3792\u001b[0m )\n\u001b[1;32m   3793\u001b[0m commit_payload \u001b[38;5;241m=\u001b[39m _prepare_commit_payload(\n\u001b[1;32m   3794\u001b[0m     operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m   3795\u001b[0m     files_to_copy\u001b[38;5;241m=\u001b[39mfiles_to_copy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     parent_commit\u001b[38;5;241m=\u001b[39mparent_commit,\n\u001b[1;32m   3799\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:4276\u001b[0m, in \u001b[0;36mHfApi.preupload_lfs_files\u001b[0;34m(self, repo_id, additions, token, repo_type, revision, create_pr, num_threads, free_memory, gitignore_content)\u001b[0m\n\u001b[1;32m   4270\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   4271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipped upload for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_lfs_additions)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(new_lfs_additions_to_upload)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m LFS file(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ignored by gitignore file).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4273\u001b[0m     )\n\u001b[1;32m   4275\u001b[0m \u001b[38;5;66;03m# Upload new LFS files\u001b[39;00m\n\u001b[0;32m-> 4276\u001b[0m \u001b[43m_upload_lfs_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4277\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_lfs_additions_to_upload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If `create_pr`, we don't want to check user permission on the revision as users with read permission\u001b[39;49;00m\n\u001b[1;32m   4284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# should still be able to create PRs even if they don't have write permission on the target branch of the\u001b[39;49;00m\n\u001b[1;32m   4285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# PR (i.e. `revision`).\u001b[39;49;00m\n\u001b[1;32m   4286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m addition \u001b[38;5;129;01min\u001b[39;00m new_lfs_additions_to_upload:\n\u001b[1;32m   4289\u001b[0m     addition\u001b[38;5;241m.\u001b[39m_is_uploaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:417\u001b[0m, in \u001b[0;36m_upload_lfs_files\u001b[0;34m(additions, repo_type, repo_id, headers, endpoint, num_threads, revision)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_actions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m LFS files to the Hub using up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_threads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m threads concurrently\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m     )\n\u001b[0;32m--> 417\u001b[0m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_wrapped_lfs_upload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiltered_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUpload \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m LFS files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(\"meyflex/Mixtral_SIG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "decd4416-8e23-4e70-bf66-c010dd475a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.8/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430323a3-efb0-4ce1-bacc-91748cc09c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prompt=\"\"\"[INST] Donnez la description détaillée correspondant au titre suivant.\\n Titre: ARC-101 [/INST]\"\"\"\n",
    "print(generate_response(prompt, merged_model))\n",
    "print(\"Le code ARC-101 correspond au Retrait de lignes dans la table tampon de l’archivage. Ce traitement permet de supprimer des lignes de la table A_ARC_DONNEE à partir des ID des objets qu'elles représentent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bda1ac25-b288-4edd-bbd0-04fb35b95f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Donnez la description détaillée correspondant au titre suivant. Titre : ARC-101 [/INST] Le titre \"ARC-101\" est probablement une référence à un type d'article, de produit ou de technologie spécifique. Cependant, sans contexte supplémentaire, il est difficile de fournir une description détaillée précise.\n",
      "\n",
      "Cela étant dit, \"ARC\" pourrait être un acronyme pour différentes choses en fonction du domaine d'application. Par exemple, dans le domaine de la technologie de l'information, \"ARC\" pourrait signifier \"Atomic Release Controller\", qui est un outil utilisé pour gérer les déploiements de logiciels. Dans ce contexte, \"ARC-101\" pourrait se référer à une version spécifique de cet outil ou à une fonctionnalité particulière.\n",
      "\n",
      "Dans le domaine de la chimie, \"ARC\" pourrait se référer à \"Acide Résorcinol-Crotonique\", qui est un composé chimique utilisé dans la recherche et l'industrie. \"ARC-101\" pourrait alors être un nom de code pour une méthode de synthèse ou une application spécifique de ce composé.\n",
      "\n",
      "Enfin, \"ARC\" pourrait également se référer à \"Advanced Recycling Center\", qui est un type de centre de traitement des déchets qui utilise des technologies avancées pour recycler les déchets en nouveaux produits. Dans ce contexte, \"ARC-101\" pourrait être le nom d'une machine ou d'un procédé spécifique utilisé dans ce type de centre de traitement.\n",
      "\n",
      "En résumé, sans contexte supplémentaire, il est difficile de fournir une description détaillée de \"ARC-101\". Cependant, il pourrait se référer à un outil de gestion de déploiement de logiciels, un composé chimique ou un procédé de recyclage avancé, en fonction du domaine d'application.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Donnez la description détaillée correspondant au titre suivant. Titre : ARC-101\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = merged_model.generate(inputs, max_new_tokens=2000)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50af61-5edd-433c-a507-79e334015bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
